{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0461210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = [1, 2]\n",
    "y = [1, -6]\n",
    "\n",
    "\n",
    "math.sqrt((x[0] - y[0])**2 + (x[1] - y[1])**2) # Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0391c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4583333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0]*y[0] + x[1]*y[1]) / (4*6)   # Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "683170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ad725e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'embedding': 1,\n",
       " 'for': 2,\n",
       " 'is': 3,\n",
       " 'sample': 4,\n",
       " 'sentence': 5,\n",
       " 'this': 6}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is a sample sentence for embedding\"\n",
    "sentence2 = \"this is sentence embedding\"\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e95ce96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=10,binary=True)\n",
    "cv.fit([sentence])\n",
    "cv.transform([sentence]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f4058cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([sentence2]).todense()\n",
    "cv.transform([\"this\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca8b6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 3, 0, 4, 5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor( [dc[s] for s in sentence.replace(',', '').split()])\n",
    "print(sentence_int) # Tokenized sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cee39227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dc)  # Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1cd901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9305,  0.1214, -0.2999],\n",
       "        [ 1.7034,  0.3775,  0.9900],\n",
       "        [ 0.6404, -1.2503,  1.0156],\n",
       "        [ 1.9391, -0.7215,  0.7416],\n",
       "        [-0.6201,  0.1858, -0.1213],\n",
       "        [ 0.0224,  0.3940,  0.8843],\n",
       "        [ 0.4107, -0.6532,  1.0826]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(dc) # 768 - 4096\n",
    "emb = torch.nn.Embedding(vocab_size, 3) # Zufallsinitialisierte Embedding-Matrix\n",
    "emb.weight.data # token 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "733bbcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4107, -0.6532,  1.0826],\n",
       "        [ 1.9391, -0.7215,  0.7416],\n",
       "        [ 0.9305,  0.1214, -0.2999],\n",
       "        [-0.6201,  0.1858, -0.1213],\n",
       "        [ 0.0224,  0.3940,  0.8843],\n",
       "        [ 0.6404, -1.2503,  1.0156],\n",
       "        [ 1.7034,  0.3775,  0.9900]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_emb = emb(sentence_int).detach() # Embedding-Vektoren für den Satz\n",
    "sentence_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5f40a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.3456, 0.8993],\n",
       "        [0.1661, 0.7828],\n",
       "        [0.3031, 0.3803]], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q, K , V\n",
    "\n",
    "d = sentence_emb.shape[1]  \n",
    "d_Q, d_K, d_V = 2, 2, 4 # Dimensionen für Q, K, V\n",
    "\n",
    "W_Q_L = torch.nn.Linear(d_Q, d, bias=False) \n",
    "# oder \n",
    "W_Q = torch.nn.Parameter(torch.rand(d, d_Q)) \n",
    "#W_Q.weight.data\n",
    "W_K = torch.nn.Parameter(torch.rand(d, d_K))\n",
    "W_V = torch.nn.Parameter(torch.rand(d, d_V))\n",
    "\n",
    "W_K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "198d58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1630, 0.2545], grad_fn=<SqueezeBackward4>),\n",
       " tensor([0.3616, 0.2698], grad_fn=<SqueezeBackward4>),\n",
       " tensor([0.4538, 0.3669, 0.6983, 0.5449], grad_fn=<SqueezeBackward4>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = sentence_emb[0] # Erster Token aus Embedding-Satz\n",
    "q_0 = x_0 @ W_Q # drei Repräsentationen    \n",
    "k_0 = x_0 @ W_K   \n",
    "v_0 = x_0 @ W_V   \n",
    "q_0, k_0, v_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f3c2c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4107, -0.6532,  1.0826],\n",
       "        [ 1.9391, -0.7215,  0.7416],\n",
       "        [ 0.9305,  0.1214, -0.2999],\n",
       "        [-0.6201,  0.1858, -0.1213],\n",
       "        [ 0.0224,  0.3940,  0.8843],\n",
       "        [ 0.6404, -1.2503,  1.0156],\n",
       "        [ 1.7034,  0.3775,  0.9900]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e7abd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sentence_emb @ W_K  # Alle Keys\n",
    "values = sentence_emb @ W_V  # Alle Values\n",
    "queries = sentence_emb @ W_Q  # Alle Queries\n",
    "\n",
    "scores_raw = queries @ keys.T # QK^T für alle Tokens / Relevanzmaß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df772a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1292, 0.1679, 0.1407, 0.1060, 0.1384, 0.1221, 0.1958],\n",
       "        [0.0621, 0.2169, 0.0995, 0.0258, 0.0890, 0.0469, 0.4598],\n",
       "        [0.1035, 0.1953, 0.1328, 0.0670, 0.1249, 0.0896, 0.2869],\n",
       "        [0.1570, 0.1058, 0.1351, 0.2069, 0.1401, 0.1716, 0.0834],\n",
       "        [0.1284, 0.1678, 0.1414, 0.1059, 0.1384, 0.1211, 0.1969],\n",
       "        [0.1308, 0.1658, 0.1408, 0.1089, 0.1389, 0.1245, 0.1903],\n",
       "        [0.0507, 0.2152, 0.0879, 0.0185, 0.0771, 0.0366, 0.5140]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "scores = scores_raw / math.sqrt(d_K)  # Skalierung\n",
    "attn_weights = F.softmax(scores, dim=1)  # Softmax über Zeilen\n",
    "attn_weights  # Aufmerksamkeitsgewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecc23010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3600, 0.4638, 1.0553, 1.0197],\n",
       "        [0.4899, 0.7595, 1.6412, 1.6270],\n",
       "        [0.4083, 0.5723, 1.2835, 1.2578],\n",
       "        [0.2786, 0.3039, 0.6773, 0.6259],\n",
       "        [0.3600, 0.4651, 1.0572, 1.0219],\n",
       "        [0.3569, 0.4569, 1.0404, 1.0041],\n",
       "        [0.5130, 0.8155, 1.7372, 1.7254]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention(Q,K,V) = softmax(QK^T/sqrt(d_K))V\n",
    "attn_output = attn_weights @ values  # Gewichtetet Summe der Values\n",
    "attn_output  # Kontextvektor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b27896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,2,1) -> 1\n",
    "# (1,2,0) -> 0\n",
    "# (4,2,1) -> 1\n",
    "# (5,2,0) -> 0\n",
    "# (6,2,1) -> 1\n",
    "# (7,2,0) -> 0\n",
    "# (1,2,1) -> 1\n",
    "# (1,2,0) -> 0\n",
    "# (1,2,1) -> 1\n",
    "# (1,2,0) -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28879b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0621, 0.2169, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1035, 0.1953, 0.1328, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1570, 0.1058, 0.1351, 0.2069, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1284, 0.1678, 0.1414, 0.1059, 0.1384, 0.0000, 0.0000],\n",
       "        [0.1308, 0.1658, 0.1408, 0.1089, 0.1389, 0.1245, 0.0000],\n",
       "        [0.0507, 0.2152, 0.0879, 0.0185, 0.0771, 0.0366, 0.5140]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = attn_weights.shape[0]\n",
    "mask = torch.tril(torch.ones(block_size, block_size))\n",
    "print(mask)\n",
    "attn_weights*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68343d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums = mask.sum(dim=1, keepdim= True)\n",
    "mask_norm = mask / row_sums\n",
    "mask_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79139770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2226, 0.7774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2398, 0.4525, 0.3077, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2596, 0.1749, 0.2234, 0.3421, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1883, 0.2461, 0.2074, 0.1553, 0.2029, 0.0000, 0.0000],\n",
       "        [0.1616, 0.2048, 0.1739, 0.1345, 0.1716, 0.1537, 0.0000],\n",
       "        [0.0507, 0.2152, 0.0879, 0.0185, 0.0771, 0.0366, 0.5140]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(block_size, block_size), diagonal=-1)\n",
    "scores_masked = scores.masked_fill(mask.T.bool(), -torch.inf)\n",
    "attn_weights_masked = torch.softmax(scores_masked, dim=1)\n",
    "attn_weights_masked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
