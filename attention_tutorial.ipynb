{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0461210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = [1, 2]\n",
    "y = [1, -6]\n",
    "\n",
    "\n",
    "math.sqrt((x[0] - y[0])**2 + (x[1] - y[1])**2) # Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0391c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4583333333333333"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0]*y[0] + x[1]*y[1]) / (4*6)   # Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "683170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ad725e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'embedding': 1,\n",
       " 'for': 2,\n",
       " 'is': 3,\n",
       " 'sample': 4,\n",
       " 'sentence': 5,\n",
       " 'this': 6}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is a sample sentence for embedding\"\n",
    "sentence2 = \"this is sentence embedding\"\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e95ce96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=10,binary=True)\n",
    "cv.fit([sentence])\n",
    "cv.transform([sentence]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f4058cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([sentence2]).todense()\n",
    "cv.transform([\"this\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca8b6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 3, 0, 4, 5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor( [dc[s] for s in sentence.replace(',', '').split()])\n",
    "print(sentence_int) # Tokenized sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cee39227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dc)  # Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1cd901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8707,  1.1182, -0.6511],\n",
       "        [-1.8573,  1.5171, -1.4076],\n",
       "        [ 0.3429,  0.6065,  1.7809],\n",
       "        [ 0.6241, -1.6505,  0.3585],\n",
       "        [ 0.5940,  1.0827, -1.6407],\n",
       "        [ 0.5672,  0.5458,  0.1611],\n",
       "        [-1.0457,  1.0252,  0.2374]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(dc) # 768 - 4096\n",
    "emb = torch.nn.Embedding(vocab_size, 3) # Zufallsinitialisierte Embedding-Matrix\n",
    "emb.weight.data # token 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "733bbcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0457,  1.0252,  0.2374],\n",
       "        [ 0.6241, -1.6505,  0.3585],\n",
       "        [ 0.8707,  1.1182, -0.6511],\n",
       "        [ 0.5940,  1.0827, -1.6407],\n",
       "        [ 0.5672,  0.5458,  0.1611],\n",
       "        [ 0.3429,  0.6065,  1.7809],\n",
       "        [-1.8573,  1.5171, -1.4076]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_emb = emb(sentence_int).detach() # Embedding-Vektoren für den Satz\n",
    "sentence_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5f40a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.7119, 0.7715],\n",
       "        [0.0393, 0.1200],\n",
       "        [0.2610, 0.1779]], requires_grad=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q, K , V\n",
    "\n",
    "d = sentence_emb.shape[1]  \n",
    "d_Q, d_K, d_V = 2, 2, 4 # Dimensionen für Q, K, V\n",
    "\n",
    "W_Q_L = torch.nn.Linear(d_Q, d, bias=False) \n",
    "# oder \n",
    "W_Q = torch.nn.Parameter(torch.rand(d, d_Q)) \n",
    "#W_Q.weight.data\n",
    "W_K = torch.nn.Parameter(torch.rand(d, d_K))\n",
    "W_V = torch.nn.Parameter(torch.rand(d, d_V))\n",
    "\n",
    "W_K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "198d58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2080, -0.1308], grad_fn=<SqueezeBackward4>),\n",
       " tensor([0.1106, 0.4931], grad_fn=<SqueezeBackward4>),\n",
       " tensor([-0.1909, -0.4126,  0.0817,  0.7000], grad_fn=<SqueezeBackward4>))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = sentence_emb[0] # Erster Token aus Embedding-Satz\n",
    "q_0 = x_0 @ W_Q # drei Repräsentationen    \n",
    "k_0 = x_0 @ W_K   \n",
    "v_0 = x_0 @ W_V   \n",
    "q_0, k_0, v_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7abd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0875,  0.1129, -0.1526,  0.1090, -0.1993, -0.5406,  0.3016],\n",
       "        [-0.3419,  0.6698, -0.8075, -0.2578, -0.6523, -1.2791,  0.3563],\n",
       "        [ 0.8805, -1.5281,  1.8977,  0.0751,  1.7889,  4.0116, -1.6254],\n",
       "        [ 0.5974, -1.1973,  1.4357,  0.5306,  1.1250,  2.1374, -0.5261],\n",
       "        [ 0.5638, -0.9002,  1.1429, -0.1853,  1.1885,  2.8529, -1.3213],\n",
       "        [ 0.6631, -0.8664,  1.1666, -0.7927,  1.5041,  4.0556, -2.2449],\n",
       "        [-0.5071,  0.5530, -0.7910,  0.9333, -1.2106, -3.4998,  2.1099]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = sentence_emb @ W_K  # Alle Keys\n",
    "values = sentence_emb @ W_V  # Alle Values\n",
    "queries = sentence_emb @ W_Q  # Alle Queries\n",
    "\n",
    "scores_raw = queries @ keys.T # QK^T für alle Tokens / Relevanzmaß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df772a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1384, 0.1595, 0.1322, 0.1591, 0.1279, 0.1005, 0.1823],\n",
       "        [0.1285, 0.2628, 0.0925, 0.1364, 0.1032, 0.0662, 0.2105],\n",
       "        [0.0666, 0.0121, 0.1366, 0.0377, 0.1265, 0.6092, 0.0113],\n",
       "        [0.1121, 0.0315, 0.2028, 0.1069, 0.1628, 0.3331, 0.0507],\n",
       "        [0.0969, 0.0344, 0.1460, 0.0571, 0.1508, 0.4892, 0.0256],\n",
       "        [0.0622, 0.0211, 0.0888, 0.0222, 0.1127, 0.6850, 0.0080],\n",
       "        [0.0725, 0.1534, 0.0593, 0.2007, 0.0441, 0.0087, 0.4613]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "scores = scores_raw / math.sqrt(d_K)  # Skalierung\n",
    "attn_weights = F.softmax(scores, dim=1)  # Softmax über Zeilen\n",
    "attn_weights  # Aufmerksamkeitsgewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc23010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0725, -0.0094, -0.0852,  0.2169],\n",
       "        [-0.1551, -0.0961, -0.2000,  0.0060],\n",
       "        [ 0.8433,  0.6507,  1.2213,  1.3927],\n",
       "        [ 0.4499,  0.4126,  0.6285,  0.9006],\n",
       "        [ 0.6777,  0.5400,  0.9773,  1.1722],\n",
       "        [ 0.9284,  0.6853,  1.3614,  1.4959],\n",
       "        [-0.6461, -0.5189, -0.7877, -0.2367]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention(Q,K,V) = softmax(QK^T/sqrt(d_K))V\n",
    "attn_output = attn_weights @ values  # Gewichtetet Summe der Values\n",
    "attn_output  # Kontextvektor "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
