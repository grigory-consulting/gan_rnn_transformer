{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "829b5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path = \"./deu.txt\"\n",
    "\n",
    "lines = open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "lines = lines[:20000]\n",
    "\n",
    "pairs = [ln.split(\"\\t\")[:2] for ln in lines] \n",
    "src_texts, tgt_texts = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f27411b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_texts[:5], tgt_texts[:5]\n",
    "PAD, UNK, BOS, EOS = 0, 1, 2, 3 # Spezialtokens \n",
    "# PAD = Padding, UNK = Unknown, \n",
    "# BOS = Begin of Sequence, EOS = End of Sequence\n",
    "VOCAB_SIZE = 20004\n",
    "def tokenize(s): return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "def build_vocab(texts, max_tokens=VOCAB_SIZE):\n",
    "    from collections import Counter\n",
    "    freq = Counter(tok for t in texts for tok in tokenize(t))\n",
    "    itos = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"] + [w for w,_ in freq.most_common(max_tokens-4)]\n",
    "    return {w:i for i,w in enumerate(itos)}, itos\n",
    "src_texts_vocab, src_itos = build_vocab(src_texts)\n",
    "tgt_texts_vocab, tgt_itos = build_vocab(tgt_texts)\n",
    "\n",
    "src_t = \"find a job\"\n",
    "tgt_t = \"Grüß Gott, Tom\"\n",
    "#src_t = (\"<bos>\",1,2,3,4,\"<pad>\",\"<pad>\",\"<eos>\") \n",
    "#tgt_t = (\"<bos>\",5,3,6,2,3,4, \"<eos>\")\n",
    "\n",
    "\n",
    "def vectorize(text, stoi, max_len, add_bos_eos=False):\n",
    "    ids = [stoi.get(tok, UNK) for tok in tokenize(text)]\n",
    "    if add_bos_eos: ids = [BOS] + ids + [EOS]\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len: ids += [PAD]*(max_len-len(ids))\n",
    "    return ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_src, max_tgt = 30, 30  # Maximale Länge \n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src = torch.tensor([vectorize(t, src_texts_vocab, max_src) for t in src_batch])\n",
    "    tgt = torch.tensor([vectorize(t, tgt_texts_vocab, max_tgt, add_bos_eos=True) for t in tgt_batch])\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    "\n",
    "dataset = list(zip(src_texts, tgt_texts))\n",
    "loader = DataLoader(dataset, batch_size= 64, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08fae447",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim, hid_dim = 128, 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab, emb_dim , padding_idx=PAD)\n",
    "        self.rnn = nn.RNN(emb_dim, hid_dim , batch_first=True) # [B, S, E] \n",
    "# für das Mini-Batch Training [B, S, E]\n",
    "# B ... Anzahl der Sätze im Batch \n",
    "# S ... Länge der Sequenz\n",
    "# E ... Embedding-Dimension \n",
    "# ohne batch_first [S, B, E]\n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden # Hidden State \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab, emb_dim, padding_idx=PAD)\n",
    "        self.rnn = nn.RNN(emb_dim, hid_dim, num_layers=1 , batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, vocab) # \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        out, h = self.rnn(x,h) \n",
    "        return self.fc(out), h # logits, hidden_state\n",
    " \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec \n",
    "    \n",
    "    def forward(self, src, tgt_in_dec):\n",
    "    # src ... englische Sätze, \n",
    "    # tgt_in_dec ... aktuelle deutsche Sätze als Eingabe für den Decoder \n",
    "        hidden_enc = self.enc(src)\n",
    "        logits, _ = self.dec(tgt_in_dec, hidden_enc) \n",
    "        # Hidden State aus dem Encoder\n",
    "        return logits \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35984737",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"I am a boy.\"\t\n",
    "target = \"Ich bin ein Junge.\"\n",
    "\n",
    "# ----------\n",
    "\n",
    "# Encoder [ \"I am a boy.\" ] -> h\n",
    "# Next Token Prediction \n",
    "# 1. Schritt Decoder [ h, <bos> ] -> \"ich\"\n",
    "# 2. Schritt Decoder [ h, (<bos>,\"ich\")] -> \"bin\" \n",
    "# 3. Schritt Decoder [ h, (<bos>,\"ich\", \"bin\")] -> \"ein\"\n",
    "# 4. Schritt Decoder [ h, (<bos>,\"ich\", \"bin\", \"ein\")] -> \"Junge\"\n",
    "# 5. Schritt Decoder [ h, (<bos>,\"ich\", \"bin\", \"ein\", \"Junge\")] -> \"<eos>\"\n",
    "\n",
    "# X = (h, (<bos>,\"ich\", \"bin\", \"ein\", \"Junge\")) -> Eingabe für Decoder \n",
    "# y = (\"ich\", \"bin\", \"ein\", \"Junge\", \"<eos>\") -> Zielvorgaben für den Loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4.5191\n",
      "ich bin nicht\n",
      "epoch 2: loss 3.8021\n",
      "ich bin nicht\n",
      "epoch 3: loss 3.4937\n",
      "ich bin\n",
      "epoch 4: loss 3.2774\n",
      "ich bin\n",
      "epoch 5: loss 3.1186\n",
      "ich bin nicht\n",
      "epoch 6: loss 2.9962\n",
      "ich bin\n",
      "epoch 7: loss 2.8955\n",
      "ich bin\n",
      "epoch 8: loss 2.8135\n",
      "ich bin\n",
      "epoch 9: loss 2.7450\n",
      "ich bin\n",
      "epoch 10: loss 2.6856\n",
      "ich bin\n",
      "epoch 11: loss 2.6367\n",
      "ich bin\n",
      "epoch 12: loss 2.5925\n",
      "ich bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model = Seq2Seq(\n",
    "    Encoder(len(src_texts_vocab), emb_dim=emb_dim, hid_dim=hid_dim),\n",
    "    Decoder(len(tgt_texts_vocab), emb_dim=emb_dim, hid_dim=hid_dim),\n",
    "                ).to(device)\n",
    "\n",
    "crit = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "opt = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "epochs = 12\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate(prompt, max_len=max_tgt):\n",
    "    model.eval()\n",
    "    src = torch.tensor([vectorize(prompt, src_texts_vocab, max_src)], device=device)\n",
    "    h = model.enc(src)\n",
    "    ys = torch.tensor([[BOS]], device=device)\n",
    "    out_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        logits, h = model.dec(ys, h)\n",
    "        next_id = logits[0, -1].argmax().item()\n",
    "        if next_id in (EOS, PAD): break\n",
    "        out_tokens.append(next_id)\n",
    "        ys = torch.cat([ys, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return \" \".join(tgt_itos[t] for t in out_tokens)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0 \n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src, tgt_in) \n",
    "        loss = crit(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Gradient-Clipping -> falls Gradient explodiert \n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"epoch {epoch+1}: loss {running_loss/len(loader):.4f}\")\n",
    "    print(translate(\"I will do my best.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56a43e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_0 -> Zufällig\n",
    "#[145,\n",
    "# 10,\n",
    "# 170,\n",
    "# 0,\n",
    "# 0,\n",
    "# 0,...,\n",
    "# \n",
    "# ]\n",
    "\n",
    "# h_1 = Wh * h_0 + Wx*145 \n",
    "# h_2 = .... \n",
    "\n",
    "\n",
    "# RNN1: h_t = Wh*h_{t-1} + Wx*x_t \n",
    "# RNN2: h_t = Wh*h_{t-1} + Wx*x_t  \n",
    "\n",
    "\n",
    "\n",
    "# RNN2(RNN1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
