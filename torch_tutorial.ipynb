{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019005a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9f5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.tensor([1.0, 2.0, 3.0]) # Tensor ist ein n-dimensionales Array\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5869, 0.8596, 0.9511],\n",
       "        [0.1601, 0.9899, 0.4052]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2,3) # 2x3 Matrix mit Zufallswerten (gleichverteilt zwischen 0 und 1)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9baf078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(2,3) # 2x3 Matrix mit Nullen\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb1c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(2,3) # 2x3 Matrix mit Einsen\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7abe49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + ones_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6905768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrixmultiplikation\n",
    "a = torch.tensor([[1., 2,], [3,4]])\n",
    "b = torch.tensor([[5., 6], [7, 8]])\n",
    "torch.matmul(a,b) # oder a @ b\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bf912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 12.],\n",
       "        [21., 32.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba50b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum() # Summe aller Elemente in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean() # Durchschnittswert aller Elemente in der Matrix a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73d66e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\") # GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # CPU\n",
    "\n",
    "device = torch.device(\"mps\") # Mac mit Apple Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e592f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradienten berechnen \n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True) # Modus: Gradient wird mitgeschleppt \n",
    "y = x**2 + 3*x + 5 \n",
    "# 2*x + 3 -> 2*2 + 3 = 7\n",
    "y.backward() # Gradient berechnen\n",
    "x.grad # Gradient ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2b13d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kosten: 4.70 (vor Update)\n",
      "Kosten: 2.61 (nach Update)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "# 10 Eingänge, 1 Ausgang -> Fully connected feed-forward neural network\n",
    "model = nn.Linear(10,1) # im Tensorflow: Dense\n",
    "# Perceptron\n",
    "# in wiss. Publikationen: FC, FFN, FFNN, MLP (Multi Layer Perceptron)\n",
    "\n",
    "loss = nn.MSELoss() # Mean Squared Error \n",
    "# loss, cost, criterion, crit, objective function, cost function \n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2) # Stochastic Gradient Descent\n",
    "# lr = Lernrate (eta, alpha); model.parameters() -> Gewichte+Bias \n",
    "\n",
    "input_data = torch.randn(10) # Zufallsinput\n",
    "y = torch.tensor([1.0]) # Zielwert, target, out, output, regr, label, ground truth\n",
    "output = model(input_data) # Vorwärtsdurchlauf, forward pass, inference, y_pred, y_hat \n",
    "\n",
    "loss_output = loss(output, y) # Unterschied zwischen Model und Realität \n",
    "                              # Anfangswert der Verlustfunktion\n",
    "\n",
    "print(f\"Kosten: {loss_output.item():.2f} (vor Update)\") \n",
    "\n",
    "# Gradientenabstiegsmethoden/Optimierer\n",
    "loss_output.backward() \n",
    "optimizer.step() # Update der Gewichte\n",
    "\n",
    "output = model(input_data)\n",
    "loss_output = loss(output, y)\n",
    "print(f\"Kosten: {loss_output.item():.2f} (nach Update)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello World im Deep Learning \n",
    "\n",
    "# MNIST Datensatz: handgeschriebene Ziffern (0-9)\n",
    "# Fashion-MNIST:  Kleidungsstücke (10 Produktkategorien) vom Zalando Online-Shop\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True) \n",
    "# Größe der Mini-Batches: Zweierpotenzen (32, 64, 128, 256,...)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a30b4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__() # Superklasse initialisieren\n",
    "        self.layer1 = nn.Linear(28*28, 128) # Eingabeschicht -> versteckte Schicht (28x28 Pixel -> 128 Neuronen)\n",
    "        self.layer2 = nn.Linear(128, 64)    # versteckte Schicht -> versteckte Schicht\n",
    "        self.dropout = nn.Dropout(0.2)          # Dropout-Schicht \n",
    "        self.layer3 = nn.Linear(64, 10)    # versteckte Schicht -> Ausgabeschicht ( 10 Produktkategorien)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Flatten: 28x28 Pixel in Vektor umwandeln\n",
    "        x = torch.relu(self.layer1(x)) # Aktivierungsfunktion ReLU\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.dropout(x)  # Dropout anwenden\n",
    "        x = self.layer3(x) # Keine Aktivierungsfunktion in der Ausgabeschicht (logits)\n",
    "        return x\n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a62752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb50654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss:2131.118208169937\n",
      "Epoch [2/20], Loss:2051.8632428646088\n",
      "Epoch [3/20], Loss:1890.6448457241058\n",
      "Epoch [4/20], Loss:1632.6226350069046\n",
      "Epoch [5/20], Loss:1384.3486088514328\n",
      "Epoch [6/20], Loss:1213.8686493635178\n",
      "Epoch [7/20], Loss:1094.782872736454\n",
      "Epoch [8/20], Loss:1007.6372411251068\n",
      "Epoch [9/20], Loss:944.1282235383987\n",
      "Epoch [10/20], Loss:894.8432307243347\n",
      "Epoch [11/20], Loss:855.1661875844002\n",
      "Epoch [12/20], Loss:824.84856569767\n",
      "Epoch [13/20], Loss:801.4100170731544\n",
      "Epoch [14/20], Loss:780.0945774316788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Vorwärtsdurchlauf\u001b[39;00m\n\u001b[32m     16\u001b[39m outputs = model(images)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m curr_loss = \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# aktueller Wert der Kostenfunktion\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Rückwärts\u001b[39;00m\n\u001b[32m     19\u001b[39m curr_loss.backward() \u001b[38;5;66;03m# Gradient berechnen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/it-schulungen.com/PyTorch_RNN_GAN_Transformer/src_live/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/it-schulungen.com/PyTorch_RNN_GAN_Transformer/src_live/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/it-schulungen.com/PyTorch_RNN_GAN_Transformer/src_live/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1385\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gits/seminars/it-schulungen.com/PyTorch_RNN_GAN_Transformer/src_live/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = NN().to(device) \n",
    "\n",
    "loss = nn.CrossEntropyLoss() # 10 Klassen \n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 20 \n",
    "\n",
    "for epoch in range(num_epochs): # Training-Loop, \n",
    "    # epoch = 1 mal hat Algorithmus Datensatz gesehen\n",
    "    model.train() # Setzen des Modells in Trainingsmodus\n",
    "    running_loss = 0.0 # Laufende Kosten\n",
    "    for images, labels in train_loader: # Mini-Batches durchlaufen\n",
    "        images, labels = images.to(device), labels.to(device) # \n",
    "        optimizer.zero_grad() # Gradient zurücksetzen\n",
    "        # Vorwärtsdurchlauf\n",
    "        outputs = model(images)\n",
    "        curr_loss = loss(outputs, labels) # aktueller Wert der Kostenfunktion\n",
    "        # Rückwärts\n",
    "        curr_loss.backward() # Gradient berechnen\n",
    "        optimizer.step()    # Gewichte updaten\n",
    "        running_loss += curr_loss.item() # Kosten aufsummieren \n",
    "    \n",
    "    print(\"Epoch [\" + str(epoch+1) + \"/\" + str(num_epochs) + \"], Loss:\" + str(running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Evaluierungsmodus\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # kein Gradient wird berechnet \n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)[-1] # argmax von outputs\n",
    "        total += labels.size(0) # Gesamte Anzahl der Labels\n",
    "        correct += (predicted==labels).sum().item() # Anzahl der richtig klassifizierten Labels\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
